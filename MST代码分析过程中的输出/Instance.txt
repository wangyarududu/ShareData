------
FLAGS
------
train-file: train.lab
test-file: null
gold-file: null
output-file: out.txt
model-name: dep.model
train: true
test: false
eval: false
loss-type: punc
second-order: false
training-iterations: 5
training-k: 1
decode-type: proj
create-forest: true
------

Creating Alphabet ... Done.
Num Features: 412
Creating Feature Vector Instance: 0
254 253 77 76 75 239 238 237 -2 
-2 
254 253 160 159 148 147 146 239 238 237 188 -2 
188 -2 
254 253 252 251 250 249 248 247 246 245 244 243 242 241 240 239 238 237 236 235 234 233 232 231 230 229 228 227 226 225 224 223 222 221 220 219 218 217 216 215 214 213 212 211 210 209 208 207 206 205 204 203 202 201 200 199 198 197 196 195 194 193 192 191 190 189 188 187 186 185 184 183 182 181 180 179 178 177 176 175 174 173 172 171 170 169 168 167 166 165 164 163 162 161 -2 
74 73 72 216 214 212 210 208 207 206 205 204 198 197 196 195 194 188 187 186 185 184 178 177 176 175 174 168 166 164 162 -2 
254 253 336 335 324 323 322 239 238 237 206 186 168 164 -2 
206 186 168 164 -2 
254 253 411 410 409 239 238 237 -2 
-2 
160 159 148 147 146 23 -2 
77 76 75 23 -2 
242 241 240 51 49 47 45 43 42 41 40 39 33 32 31 30 29 23 22 21 20 19 13 12 11 10 9 3 1 -2 
77 76 75 74 73 72 71 70 69 68 67 66 65 64 63 62 61 60 59 58 57 56 55 54 53 52 51 50 49 48 47 46 45 44 43 42 41 40 39 38 37 36 35 34 33 32 31 30 29 28 27 26 25 24 23 22 21 20 19 18 17 16 15 14 13 12 11 10 9 8 7 6 5 4 3 2 1 0 -2 
336 335 324 323 322 41 21 3 -2 
77 76 75 41 21 3 -2 
411 410 409 -2 
77 76 75 -2 
242 241 240 125 123 121 119 117 116 115 114 113 288 107 106 105 104 103 97 96 95 94 93 87 86 85 84 83 -2 
160 159 158 157 156 155 154 153 152 151 150 149 148 147 146 74 73 72 145 144 143 142 141 140 139 138 137 136 135 134 133 132 131 130 129 128 127 126 125 124 123 122 121 120 119 118 117 116 115 114 113 112 111 110 109 108 107 106 105 104 103 102 101 100 99 98 97 96 95 94 93 92 91 90 89 88 87 86 85 84 83 82 81 80 79 78 -2 
336 335 324 323 322 95 -2 
160 159 148 147 146 95 -2 
411 410 409 379 -2 
160 159 148 147 146 379 -2 
336 335 334 333 332 331 330 329 328 327 326 325 324 323 322 74 73 72 321 320 319 318 317 316 315 314 313 312 311 310 309 308 307 306 305 304 303 302 301 300 299 298 297 296 295 294 293 116 292 291 290 289 288 287 286 285 284 283 282 281 280 279 278 277 276 275 274 273 272 271 270 269 268 267 266 265 264 263 262 261 260 259 258 257 256 255 -2 
242 241 240 301 299 297 295 293 116 292 291 290 111 284 283 282 281 280 274 273 272 271 270 264 263 262 261 260 -2 
411 410 409 74 73 72 408 407 406 405 404 403 402 401 400 399 398 397 396 395 394 393 392 391 390 389 388 387 386 385 384 383 382 381 380 379 378 377 376 375 374 373 372 371 370 369 368 367 366 365 364 363 362 361 360 359 358 357 356 355 354 353 352 351 350 349 348 347 346 345 344 343 342 341 340 339 338 337 -2 
242 241 240 388 386 384 382 380 379 378 377 376 370 369 368 367 366 360 359 358 357 356 350 349 348 347 346 340 338 -2 
411 410 409 293 289 357 -2 
336 335 324 323 322 293 357 -2 
-3 
411 
410 
409 
74 
73 
72 
408 
407 
406 
405 
404 
403 
402 
401 
400 
399 
398 
397 
396 
395 
394 
393 
392 
391 
390 
389 
388 
387 
386 
385 
384 
383 
382 
381 
380 
379 
378 
377 
376 
375 
374 
373 
372 
371 
370 
369 
368 
367 
366 
365 
364 
363 
362 
361 
360 
359 
358 
357 
356 
355 
354 
353 
352 
351 
350 
349 
348 
347 
346 
345 
344 
343 
342 
341 
340 
339 
338 
337 
336 
335 
334 
333 
332 
331 
330 
329 
328 
327 
326 
325 
324 
323 
322 
74 
73 
72 
321 
320 
319 
318 
317 
316 
315 
314 
313 
312 
311 
310 
309 
308 
307 
306 
305 
304 
303 
302 
301 
300 
299 
298 
297 
296 
295 
294 
293 
116 
292 
291 
290 
289 
288 
287 
286 
285 
284 
283 
282 
281 
280 
279 
278 
277 
276 
275 
274 
273 
272 
271 
270 
269 
268 
267 
266 
265 
264 
263 
262 
261 
260 
259 
258 
257 
256 
255 
254 
253 
252 
251 
250 
249 
248 
247 
246 
245 
244 
243 
242 
241 
240 
239 
238 
237 
236 
235 
234 
233 
232 
231 
230 
229 
228 
227 
226 
225 
224 
223 
222 
221 
220 
219 
218 
217 
216 
215 
214 
213 
212 
211 
210 
209 
208 
207 
206 
205 
204 
203 
202 
201 
200 
199 
198 
197 
196 
195 
194 
193 
192 
191 
190 
189 
188 
187 
186 
185 
184 
183 
182 
181 
180 
179 
178 
177 
176 
175 
174 
173 
172 
171 
170 
169 
168 
167 
166 
165 
164 
163 
162 
161 
160 
159 
158 
157 
156 
155 
154 
153 
152 
151 
150 
149 
148 
147 
146 
74 
73 
72 
145 
144 
143 
142 
141 
140 
139 
138 
137 
136 
135 
134 
133 
132 
131 
130 
129 
128 
127 
126 
125 
124 
123 
122 
121 
120 
119 
118 
117 
116 
115 
114 
113 
112 
111 
110 
109 
108 
107 
106 
105 
104 
103 
102 
101 
100 
99 
98 
97 
96 
95 
94 
93 
92 
91 
90 
89 
88 
87 
86 
85 
84 
83 
82 
81 
80 
79 
78 
77 
76 
75 
74 
73 
72 
71 
70 
69 
68 
67 
66 
65 
64 
63 
62 
61 
60 
59 
58 
57 
56 
55 
54 
53 
52 
51 
50 
49 
48 
47 
46 
45 
44 
43 
42 
41 
40 
39 
38 
37 
36 
35 
34 
33 
32 
31 
30 
29 
28 
27 
26 
25 
24 
23 
22 
21 
20 
19 
18 
17 
16 
15 
14 
13 
12 
11 
10 
9 
8 
7 
6 
5 
4 
3 
2 
1 
0 
-4
[Ljava.lang.String;@677327b6-5[Ljava.lang.String;@29453f44-6[Ljava.lang.String;@5e2de80c-73|1:0 3|2:0 0|3:0 3|4:0 3|5:0-1Num Feats: 412
Num Edge Labels: 1
About to train
Num Feats: 412
========================
Iteration: 0
========================
Processed: 
  1 instances
Training iter took: 34
========================
Iteration: 1
========================
Processed: 
  1 instances
Training iter took: 10
========================
Iteration: 2
========================
Processed: 
  1 instances
Training iter took: 38
========================
Iteration: 3
========================
Processed: 
  1 instances
Training iter took: 10
========================
Iteration: 4
========================
Processed: 
  1 instances
Training iter took: 16
hehe
Saving model ... done.
